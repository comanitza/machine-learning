{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9993f6a4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:32.306257Z",
     "iopub.status.busy": "2024-02-08T22:47:32.305382Z",
     "iopub.status.idle": "2024-02-08T22:47:33.193370Z",
     "shell.execute_reply": "2024-02-08T22:47:33.192075Z"
    },
    "papermill": {
     "duration": 0.898237,
     "end_time": "2024-02-08T22:47:33.196041",
     "exception": false,
     "start_time": "2024-02-08T22:47:32.297804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iris/Iris.csv\n",
      "/kaggle/input/iris/database.sqlite\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3c5dc",
   "metadata": {
    "papermill": {
     "duration": 0.004663,
     "end_time": "2024-02-08T22:47:33.206084",
     "exception": false,
     "start_time": "2024-02-08T22:47:33.201421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intro\n",
    "In this small notebook we will classify the well know and easy Iris dataset using a new ural network implemented with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c4db6",
   "metadata": {
    "papermill": {
     "duration": 0.004383,
     "end_time": "2024-02-08T22:47:33.215202",
     "exception": false,
     "start_time": "2024-02-08T22:47:33.210819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf53701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:33.226415Z",
     "iopub.status.busy": "2024-02-08T22:47:33.225839Z",
     "iopub.status.idle": "2024-02-08T22:47:37.923579Z",
     "shell.execute_reply": "2024-02-08T22:47:37.922335Z"
    },
    "papermill": {
     "duration": 4.706342,
     "end_time": "2024-02-08T22:47:37.926118",
     "exception": false,
     "start_time": "2024-02-08T22:47:33.219776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cd955",
   "metadata": {
    "papermill": {
     "duration": 0.006179,
     "end_time": "2024-02-08T22:47:37.937824",
     "exception": false,
     "start_time": "2024-02-08T22:47:37.931645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the data, minor EDA and preprocessing\n",
    "In this section we will load the data and do a very quick EDA on it.\n",
    "\n",
    "We split our dataset in X (features) and y (labels), the label is the species of the plant.\n",
    "The labels will be encoded using the LabelEncoder, and the features will be scaled.\n",
    "\n",
    "At the end of this section we split X and y to train and test end convert them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7912497a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:37.949620Z",
     "iopub.status.busy": "2024-02-08T22:47:37.948744Z",
     "iopub.status.idle": "2024-02-08T22:47:37.982521Z",
     "shell.execute_reply": "2024-02-08T22:47:37.981390Z"
    },
    "papermill": {
     "duration": 0.04251,
     "end_time": "2024-02-08T22:47:37.984947",
     "exception": false,
     "start_time": "2024-02-08T22:47:37.942437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/iris/Iris.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed51233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:37.996410Z",
     "iopub.status.busy": "2024-02-08T22:47:37.996051Z",
     "iopub.status.idle": "2024-02-08T22:47:38.005939Z",
     "shell.execute_reply": "2024-02-08T22:47:38.004968Z"
    },
    "papermill": {
     "duration": 0.018232,
     "end_time": "2024-02-08T22:47:38.008168",
     "exception": false,
     "start_time": "2024-02-08T22:47:37.989936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset: (150, 6)\n",
      "distinct species:  ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# the sape of the dataset\n",
    "print(f\"shape of the dataset: {df.shape}\")\n",
    "\n",
    "# the unique values for the Species column, which is our label\n",
    "print(\"distinct species: \", df[\"Species\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4806dcfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:38.019999Z",
     "iopub.status.busy": "2024-02-08T22:47:38.019540Z",
     "iopub.status.idle": "2024-02-08T22:47:38.033053Z",
     "shell.execute_reply": "2024-02-08T22:47:38.032136Z"
    },
    "papermill": {
     "duration": 0.021914,
     "end_time": "2024-02-08T22:47:38.035035",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.013121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we define out X and y and use label encoder for our labels\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "X = df[[\"SepalLengthCm\",  \"SepalWidthCm\",  \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = labelEncoder.fit_transform(df[\"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9ccd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:38.047199Z",
     "iopub.status.busy": "2024-02-08T22:47:38.046631Z",
     "iopub.status.idle": "2024-02-08T22:47:38.055713Z",
     "shell.execute_reply": "2024-02-08T22:47:38.054963Z"
    },
    "papermill": {
     "duration": 0.017286,
     "end_time": "2024-02-08T22:47:38.057588",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.040302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "labelEncoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20e37fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:38.069723Z",
     "iopub.status.busy": "2024-02-08T22:47:38.069151Z",
     "iopub.status.idle": "2024-02-08T22:47:38.104648Z",
     "shell.execute_reply": "2024-02-08T22:47:38.103420Z"
    },
    "papermill": {
     "duration": 0.044626,
     "end_time": "2024-02-08T22:47:38.107369",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.062743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac189ff",
   "metadata": {
    "papermill": {
     "duration": 0.004797,
     "end_time": "2024-02-08T22:47:38.117506",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.112709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the Model\n",
    "Next we will define out model. It's an easy model, it consists of three fully connected layers, with ReLU activation layres between them. We use a LogSoftmx at the end of the network.\n",
    "\n",
    "We output 3 values as this is the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0ece80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:38.128990Z",
     "iopub.status.busy": "2024-02-08T22:47:38.128544Z",
     "iopub.status.idle": "2024-02-08T22:47:38.135740Z",
     "shell.execute_reply": "2024-02-08T22:47:38.134302Z"
    },
    "papermill": {
     "duration": 0.015444,
     "end_time": "2024-02-08T22:47:38.137818",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.122374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IrisNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNNModel, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=4, out_features=40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=40, out_features=20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=20, out_features=3),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        yHat = self.net(X)\n",
    "\n",
    "        return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421886c5",
   "metadata": {
    "papermill": {
     "duration": 0.00494,
     "end_time": "2024-02-08T22:47:38.148565",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.143625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the model\n",
    "Here we will train out model, first we declare the variables we need and the we do the actual training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c185e0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:38.161809Z",
     "iopub.status.busy": "2024-02-08T22:47:38.161239Z",
     "iopub.status.idle": "2024-02-08T22:47:41.041021Z",
     "shell.execute_reply": "2024-02-08T22:47:41.038788Z"
    },
    "papermill": {
     "duration": 2.889411,
     "end_time": "2024-02-08T22:47:41.043503",
     "exception": false,
     "start_time": "2024-02-08T22:47:38.154092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120\n"
     ]
    }
   ],
   "source": [
    "model = IrisNNModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "\n",
    "datasetTrain = TensorDataset(X_train, y_train)\n",
    "dataloaderTrain = DataLoader(datasetTrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "datasetTrain = TensorDataset(X_train, y_train)\n",
    "dataloaderTrain = DataLoader(datasetTrain, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c21a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:41.055834Z",
     "iopub.status.busy": "2024-02-08T22:47:41.055268Z",
     "iopub.status.idle": "2024-02-08T22:47:51.487832Z",
     "shell.execute_reply": "2024-02-08T22:47:51.486827Z"
    },
    "papermill": {
     "duration": 10.441797,
     "end_time": "2024-02-08T22:47:51.490617",
     "exception": false,
     "start_time": "2024-02-08T22:47:41.048820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0, batch 0, loss 1.04355180\n",
      "training epoch 50, batch 0, loss 0.09736168\n",
      "training epoch 100, batch 0, loss 0.02706866\n",
      "training epoch 150, batch 0, loss 0.10061383\n",
      "training epoch 200, batch 0, loss 0.05996988\n",
      "training epoch 250, batch 0, loss 0.01234431\n",
      "training epoch 300, batch 0, loss 0.02686932\n",
      "training epoch 350, batch 0, loss 0.00119282\n",
      "training epoch 400, batch 0, loss 0.00884304\n",
      "training epoch 450, batch 0, loss 0.01071633\n",
      "training epoch 500, batch 0, loss 0.00003681\n",
      "training epoch 550, batch 0, loss 0.00473316\n",
      "training epoch 600, batch 0, loss 0.00325835\n",
      "training epoch 650, batch 0, loss 0.00141550\n",
      "training epoch 700, batch 0, loss 0.00126614\n",
      "training epoch 750, batch 0, loss 0.00251437\n",
      "training epoch 800, batch 0, loss 0.00063520\n",
      "training epoch 850, batch 0, loss 0.00000292\n",
      "training epoch 900, batch 0, loss 0.00034853\n",
      "training epoch 950, batch 0, loss 0.00029381\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for i, (X_batch, y_batch) in enumerate(dataloaderTrain):\n",
    "\n",
    "        yHatPred = model.forward(X_batch)\n",
    "\n",
    "        loss = lossFunction(yHatPred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i == 0 and epoch % 50 == 0:\n",
    "            print(f\"training epoch {epoch}, batch {i}, loss {loss.item():.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606d0ae",
   "metadata": {
    "papermill": {
     "duration": 0.006102,
     "end_time": "2024-02-08T22:47:51.504651",
     "exception": false,
     "start_time": "2024-02-08T22:47:51.498549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making predictions\n",
    "First we are going to define the dataloader we need, and set our model in eval mode, and the we will do the predictions for our test data.\n",
    "As we have small test dataset we will print the actual predictions for all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5446993d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:51.519187Z",
     "iopub.status.busy": "2024-02-08T22:47:51.518760Z",
     "iopub.status.idle": "2024-02-08T22:47:51.524621Z",
     "shell.execute_reply": "2024-02-08T22:47:51.523648Z"
    },
    "papermill": {
     "duration": 0.016055,
     "end_time": "2024-02-08T22:47:51.526977",
     "exception": false,
     "start_time": "2024-02-08T22:47:51.510922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "datasetTest = TensorDataset(X_test, y_test)\n",
    "dataloaderTest = DataLoader(datasetTest, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceac7507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T22:47:51.542340Z",
     "iopub.status.busy": "2024-02-08T22:47:51.541951Z",
     "iopub.status.idle": "2024-02-08T22:47:51.555851Z",
     "shell.execute_reply": "2024-02-08T22:47:51.554553Z"
    },
    "papermill": {
     "duration": 0.024343,
     "end_time": "2024-02-08T22:47:51.558057",
     "exception": false,
     "start_time": "2024-02-08T22:47:51.533714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### prediction for batch 0, batch loss: 0.0005\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 1 predicted value: 1\n",
      "### prediction for batch 1, batch loss: 0.0000\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 1 predicted value: 1\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 2 predicted value: 2\n",
      "actual value: 0 predicted value: 0\n",
      "actual value: 0 predicted value: 0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (X_batch, y_batch) in enumerate(dataloaderTest):\n",
    "\n",
    "        yHat = model.forward(X_batch)\n",
    "        loss = lossFunction(yHat, y_batch)\n",
    "\n",
    "        print(f\"### prediction for batch {i}, batch loss: {loss.item():.4f}\")\n",
    "\n",
    "        for i in range(yHat.shape[0]):\n",
    "            # we use argmax on the result to determine the max value, that is our prediction\n",
    "            print(f\"actual value: {y_batch[i].item()}\", f\"predicted value: {torch.argmax(yHat[i], dim=0).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e78506",
   "metadata": {
    "papermill": {
     "duration": 0.00639,
     "end_time": "2024-02-08T22:47:51.571128",
     "exception": false,
     "start_time": "2024-02-08T22:47:51.564738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finish\n",
    "You have made it to the finish, thank you! Please upvote :)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 19,
     "sourceId": 420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.870196,
   "end_time": "2024-02-08T22:47:53.404480",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-08T22:47:29.534284",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
